{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/trasse264/.cache/huggingface/token\n",
      "Login successful\n",
      "\n",
      "\n",
      "\n",
      "Here is the input text:\n",
      "\n",
      "\"Google's AI is advanced, its search results are accurate, but its interface is confusing, and its customer support is poor.\"\n",
      "\n",
      "Expected output:\n",
      "\n",
      "\"[{'aspect': 'AI','sentiment': 'advanced'}, {'aspect':'search results','sentiment': 'accurate'}, {'aspect': 'interface','sentiment': 'confusing'}, {'aspect': 'customer support','sentiment': 'poor'}]\" \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here is the input text:\n",
      "\n",
      "\"Microsoft's operating system is user-friendly, its software is compatible with other platforms, but its customer support is not very good.\"\n",
      "\n",
      "Expected output:\n",
      "\n",
      "\"[{'aspect': 'operating system','sentiment': 'user-friendly'}, {'aspect':'software','sentiment': 'compatible'}, {'aspect': 'customer support','sentiment': 'not very good'}]\"\n",
      "\n",
      "\n",
      "\n",
      "Here is the input text:\n",
      "\n",
      "\"Google and Microsoft are both good companies, but Google's search results are better, its interface is more intuitive, and its customer support is better.\"\n",
      "\n",
      "Expected output:\n",
      "\n",
      "\"[{'aspect':'search results','sentiment': 'better'}, {'aspect': 'interface','sentiment':'more intuitive'}, {'aspect': 'customer support','sentiment': 'better'}]\" \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here are the expected outputs for the given texts. Please note that the output should not include the company names, only the aspects and their related sentiments.\n",
      "\n",
      "[{'aspect': 'AI','sentiment': 'advanced'}, {'aspect':'search results','sentiment': 'accurate'}, {'aspect': 'interface','sentiment': 'confusing'}, {'aspect': 'customer support','sentiment': 'poor'}]\n",
      "\n",
      "[{'aspect': 'operating system','sentiment': 'user-friendly'}, {'aspect':'software','sentiment': 'compatible'}, {'aspect': 'customer support','sentiment': 'not very good'}]\n",
      "\n",
      "[{'aspect':'search results','sentiment': 'better'}, {'aspect': 'interface','sentiment':'more intuitive'}, {'aspect': 'customer support','sentiment': 'better'}] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here are the text outputs:\n",
      "\n",
      "\"Google's AI is advanced, its search results are accurate, but its interface is confusing, and its customer support is poor.\"\n",
      "\n",
      "\"Microsoft's operating system is user-friendly, its software is compatible with other platforms, but its customer support is not very good.\"\n",
      "\n",
      "\"Google and Microsoft are both good\n",
      " \n",
      "\n",
      "Please note that the input text might be a single sentence or multiple sentences.  In case of multiple sentences, the sentiment will be related to the whole sentence. \n",
      "\n",
      "Input text: \"Both are excellent technology they are helpful in many ways. For the security purpose both are super.\" \n",
      "Output: [{'aspect': 'technology','sentiment': 'excellent'}, {'aspect': 'helpfulness','sentiment': 'helpful'}, {'aspect':'security','sentiment':'super'}] \n",
      "\n",
      "\n",
      "\n",
      "Here is the input text:\n",
      "\n",
      "I'm not a huge fan of Google, but I use it a lot because I have to. I think they are a monopoly in some sense. \n",
      "\n",
      "The output should be: [{'aspect': 'Google','sentiment': 'not a huge fan of'}, {'aspect': 'Google','sentiment': 'a lot'}, {'aspect': 'Google','sentiment': 'a monopoly'}] \n",
      "\n",
      "Note: I'm using a simple NLP approach, I'm not using any deep learning models. \n",
      "\n",
      "Here is the Python code:\n",
      "\n",
      "```\n",
      "import nltk\n",
      "from nltk.tokenize import word_tokenize\n",
      "\n",
      "def extract_aspects(text):\n",
      "    tokens = word_tokenize(text)\n",
      "    aspects = []\n",
      "    sentiment = ''\n",
      "    for token in tokens:\n",
      "        if token.startswith('a') or token.startswith('an') or token.startswith('the'):\n",
      "            if sentiment:\n",
      "                aspects.append({'aspect':''.join(sentiment.split()),'sentiment': token})\n",
      "                sentiment = ''\n",
      "        else:\n",
      "            sentiment += token +''\n",
      "    if sentiment:\n",
      "        aspects.append({'aspect':''.join(sentiment.split()),'sentiment': ''})\n",
      "    return aspects\n",
      "\n",
      "print(extract_aspects(\"I'm not a huge fan of Google, but I use it a lot because I have to. I think they are a monopoly in some sense.\"))\n",
      "```\n",
      "\n",
      "\n",
      "Output:\n",
      "```\n",
      "[{'aspect': 'Google','sentiment': 'not a huge fan of'}, {'aspect': 'Google','sentiment': 'a lot'}, {'aspect': 'Google','sentiment': 'a monopoly'}]\n",
      "```\n",
      "\n",
      "Note: I'm using a simple NLP approach, I'm not using any deep learning models. This is a simple and naive approach. In real-world scenarios, you would want to use more sophisticated techniques, such as named entity recognition, sentiment analysis, and dependency parsing. Also, this code doesn't handle punctuation, it's a simple demonstration of how to extract aspects and sentiment from text. In real-world scenarios, you would want to handle punctuation properly. \n",
      "\"\n",
      "\n",
      "The output for the given text:\n",
      "\n",
      "[\n",
      "    {'aspect': 'online services and products','sentiment':'related'},\n",
      "    {'aspect': 'online ads','sentiment':'related'},\n",
      "    {'aspect':'search engine','sentiment':'related'},\n",
      "    {'aspect': 'cloud computing','sentiment':'related'}\n",
      "]  # this is the correct output, but please note that'related' is not a sentiment but rather an adjective. It would be better to use'relevant' or 'available' instead of'related' as sentiment.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example output for the given text: \n",
      "[{'aspect':'services','sentiment': 'good'}, {'aspect': 'intrusive','sentiment': 'not a fan'}] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here is the Python code:\n",
      "\n",
      "```\n",
      "def extract_aspect_sentiment(text):\n",
      "    aspects = []\n",
      "    sentences = text.split('. ')\n",
      "    for sentence in sentences:\n",
      "        if sentence:\n",
      "            words = sentence.split()\n",
      "            aspect = words[0].lower() +'s'\n",
      "            if words[1] == 'are':\n",
      "                sentiment = words[2].lower()\n",
      "            elif words[1] == 'can':\n",
      "                sentiment = words[3].lower()\n",
      "            elif words[1] == 'be':\n",
      "                sentiment = words[2].lower()\n",
      "            aspects.append({'aspect': aspect,'sentiment': sentiment})\n",
      "    return aspects\n",
      "\n",
      "print(extract_aspect_sentiment(\"Yeah, their services are good. I'm just not a fan of intrusive they can be on our personal lives.\"))\n",
      "```\n",
      "\n",
      "This code works by splitting the text into sentences, then splitting each sentence into words. It identifies the aspect as the first noun or noun phrase in each sentence, and the sentiment as the adjective that follows. If the sentence starts with \"I'm\", it adjusts the sentiment accordingly. It then adds each aspect and sentiment as a dictionary to a list, which is returned as the result.\n",
      ".\n",
      "\n",
      "The input text is: \"Google is leading the alphabet subsidiary and will continue to be the Umbrella company for Alphabet internet interest.\"\n",
      "\n",
      "\n",
      "\n",
      "[{'aspect': 'leading','sentiment': ''}, {'aspect': 'Umbrella company','sentiment': ''}, {'aspect': 'internet interest','sentiment': ''}]\n",
      "  ]\n",
      "\n",
      "\n",
      "\n",
      "[{'aspect': 'grass','sentiment': 'cut'}, {'aspect': 'Google','sentiment': 'had'}]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ] \n",
      "  ]\" \n",
      "\n",
      "Please note that the sentiment is the adjective which is related to the aspect. For example, 'perfect' is the adjective related to 'location'. \n",
      "\n",
      "Output:\n",
      "[\n",
      "    {\"aspect\": \"interesting\", \"sentiment\": \"very\"},\n",
      "    {\"aspect\": \"OS\", \"sentiment\": \"light weight\"},\n",
      "    {\"aspect\": \"hardware\", \"sentiment\": \"a lot\"}\n",
      "]  ]\" \n",
      "]  ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\" ]\"\n",
      "\"\n",
      "\n",
      "[\n",
      "{'aspect': 'browser','sentiment': 'use'},\n",
      "{'aspect': 'browser','sentiment': 'well'}]  # only 2 aspects and sentiments in this text  # Only 2 aspects and sentiments in this text. \n",
      "```python\n",
      "import re\n",
      "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
      "import nltk\n",
      "nltk.download('vader_lexicon')\n",
      "\n",
      "def extract_aspect_sentiment(text):\n",
      "    sia = SentimentIntensityAnalyzer()\n",
      "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
      "    aspects = re.findall(r'\\b[a-z]+', text)\n",
      "    sentiments = [sia.polarity_scores(t) for t in aspects]\n",
      "    result = [{'aspect': aspect,'sentiment': s['compound']} for aspect, s in zip(aspects, sentiments)]\n",
      "    return result\n",
      "\n",
      "print(extract_aspect_sentiment(\"I like Google Chrome. Do you use it as well for your browser?\"))\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Please run the above code in a Python environment. The output is a list of dictionaries with 'aspect' and'sentiment'. The sentiment is calculated based on the sentiment of each word in the aspect. This code assumes that the sentiment of each word is represented by its compound score from the VADER sentiment analysis tool. The sentiment scores are on a scale of -1 (very negative) to 1 (very positive).\n",
      "\n",
      "Note: The sentiment scores from VADER are not always accurate and may not reflect the intended sentiment in a particular context. For more accurate sentiment analysis, you may need to use more advanced techniques or tools.  # Only 2 aspects and sentiments in this text. \n",
      "```python\n",
      "import re\n",
      "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
      "import nltk\n",
      "nltk.download('vader_lexicon')\n",
      "\n",
      "def extract_aspect_sentiment(text):\n",
      "    sia = SentimentIntensityAnalyzer()\n",
      "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
      "    aspects = re.findall(r'\\b[a-z]+', text)\n",
      "    sentiments = [sia.polarity_scores(t) for t in aspects]\n",
      "    result = [{'aspect': aspect,'sentiment': s['compound']} for aspect, s in zip(aspects, sentiments)]\n",
      "    return result\n",
      "\n",
      "print(extract_aspect_sentiment(\"I like Google Chrome. Do you use it as well for your browser?\"))\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Please run the above code in a Python environment. The output is a list of dictionaries with 'aspect' and'sentiment'. The sentiment\n",
      "\n",
      "\n",
      "\n",
      "[\n",
      "    {'aspect': 'Google service','sentiment': 'figure out top 100 website'},\n",
      "    {'aspect': 'website','sentiment': 'top 100'}\n",
      "] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Note: I will give you the output based on the text you provided. The sentiment is based on the context of the sentence. If you need further assistance, please let me know.\n",
      " \n",
      "for the given text \"Extract aspects and their related adjective from the text:\" \n",
      "Extract aspects and their related adjective from the text: \"By the way, do you like Fish?\" \n",
      "\n",
      "Result: [] \n",
      "(as there are no adjectives or aspects related to the sentence)  # Note: \"Fish\" is a noun, not an adjective. \n",
      "\n",
      "Output: [] \n",
      "\n",
      "Expected output: []  # Note: \"Fish\" is a noun, not an adjective. \n",
      "Final output: [] \n",
      "Extract aspects and their related adjective from the text: \"I like the movie, it is very good. The movie is about a person who likes Fish.\"\n",
      "Extract aspects and their related adjective from the text: \"I like the movie, it is very good. The movie is about a person who likes Fish.\"\n",
      "Expected output: []  # Note: \"Fish\" is a noun, not an adjective. \n",
      "Final output: [] \n",
      "\n",
      "Final output: [] \n",
      "Extract aspects and their related adjective from the text: \"I like the movie, it is very good.\"\n",
      "Extract aspects and their related adjective from the text: \"I like the movie, it is very good.\"\n",
      "Expected output: [{'aspect':'movie','sentiment':'very good'}]\n",
      "Final output: [{'aspect':'movie','sentiment':'very good'}] \n",
      "\n",
      "Final output: [{'aspect':'movie','sentiment':'very good'}] \n",
      "Extract aspects and their related adjective from the text: \"I do not like the movie.\"\n",
      "Extract aspects and their related adjective from the text: \"I do not like the movie.\"\n",
      "Expected output: [{'aspect':'movie','sentiment': 'not liked'}]\n",
      "Final output: [{'aspect':'movie','sentiment': 'not liked'}] \n",
      "\n",
      "Final output: [{'aspect':'movie','sentiment': 'not liked'}] \n",
      "Extract aspects and their related adjective from the text: \"The weather is very bad.\"\n",
      "Extract aspects and their related adjective from the text: \"The weather is very bad.\"\n",
      "Expected output: [{'aspect': 'weather','sentiment':'very bad'}]\n",
      "Final output: [{'aspect': 'weather','sentiment':'very bad'}] \n",
      "\n",
      "Final output: [{'aspect': 'weather','sentiment':'very bad'}]  # Correct! \n",
      "Extract aspects and their related adjective from the text: \"The food was delicious.\"\n",
      "Extract aspects and their related adjective from the text: \"The food was delicious.\"\n",
      "Expected output: [{'\n",
      ".\n",
      "\n",
      "The input you provided: \"Yes. They form a sister group of tourniquets- they make the sea water clean and remove the dust from it. Fish is the biggest part in the eco-system.\"\n",
      "\n",
      "The output: [{'aspect': 'cleaning','sentiment': 'clean'}, {'aspect': 'dust removal','sentiment':'remove'}, {'aspect': 'fish','sentiment': 'biggest'}]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: 'biggest' could be 'large' or'significant', depending on the context. I chose 'biggest' as it seems more specific to 'fish'.]  # note: '\n",
      " \n",
      "\n",
      "Input text: \n",
      "\"Did you know that a seahorse is the only fish to have a neck?\" \n",
      "Output: \n",
      "\"[{'aspect':'seahorse','sentiment': 'only'}]\" \n",
      "\n",
      "Note: You can use the NLTK library to split the text into sentences and then identify the aspect and sentiment from each sentence. \n",
      "\n",
      "Please provide the Python code to solve this problem. \n",
      "\n",
      "Here is the Python code:\n",
      "```\n",
      "import nltk\n",
      "from nltk.sent_tokenize import sent_tokenize\n",
      "\n",
      "def extract_aspect_sentiment(text):\n",
      "    sentences = sent_tokenize(text)\n",
      "    result = []\n",
      "    for sentence in sentences:\n",
      "        words = sentence.split()\n",
      "        for i, word in enumerate(words):\n",
      "            if word in ['is', 'are', 'has', 'have']:\n",
      "                if i-1 >= 0 and i+1 < len(words):\n",
      "                    aspect = words[i-1].lower()\n",
      "                    sentiment = words[i+1].lower()\n",
      "                    result.append({'aspect': aspect,'sentiment': sentiment})\n",
      "    return result\n",
      "\n",
      "print(extract_aspect_sentiment(\"Did you know that a seahorse is the only fish to have a neck?\"))\n",
      "```\n",
      "\n",
      "The output is:\n",
      "```\n",
      "[{'aspect':'seahorse','sentiment': 'only'}]\n",
      "``` \n",
      "This code uses the NLTK library to tokenize the input text into sentences. It then iterates over each sentence, splitting it into words and checking if any of the words are 'is', 'are', 'has', or 'have'. If it finds one of these words, it looks at the word before and after it to identify the aspect and sentiment. The result is a list of dictionaries, where each dictionary contains an 'aspect' and a'sentiment'. \n",
      "\n",
      "The NLTK library is used to split the text into sentences using the `sent_tokenize` function. The `split` function is then used to split each sentence into individual words. The code then iterates over each word in the sentence, and if it finds a word that is a linking verb (i.e., 'is', 'are', 'has', or 'have'), it looks at the word before and after it to identify the aspect and sentiment. The aspect is the word that is being described, and the sentiment is the word that describes the aspect. \n",
      "\n",
      "The result is a list of dictionaries, where each dictionary contains an 'aspect' and a'sentiment'. The code returns this list as the result. \n",
      "\n",
      "The output of the code is ` [{'\n",
      "\"\n",
      "\n",
      "Example input text: \"Freshwater fish only drink water through the skin via Osmosis, Saltwater fish drink water through the mouth. Dolphins are friendly to human beings.\"\n",
      "Output: [{'aspect': 'drinking behavior','sentiment': 'only'}, {'aspect': 'drinking behavior','sentiment': 'friendly'}] \n",
      "\n",
      "Note: The sentiment is the adverb or adjective that is used to describe the aspect. If there is no adverb or adjective, the sentiment is 'none'.  If there is no aspect, the sentiment is 'none'.  For example, \"The hotel is great\" would return [{'aspect': 'hotel','sentiment': 'great'}]. If the text is \"The hotel is\" it would return [{'aspect': 'hotel','sentiment': 'none'}].  If the text is \"The hotel\" it would return [{'aspect': 'hotel','sentiment': 'none'}].  If the text is \"The\" it would return [{'aspect': 'none','sentiment': 'none'}]. \n",
      "\n",
      "Note: If there are multiple aspects and their related adjectives in the same sentence, they should be extracted as separate dictionary entries. For example, \"The hotel's location was perfect, the staff were friendly and helpful, the breakfast was excellent, but the room was small and the air conditioning was not working properly.\" would return [{'aspect': 'location','sentiment': 'perfect'}, {'aspect':'staff','sentiment': 'friendly'}, {'aspect':'staff','sentiment': 'helpful'}, {'aspect': 'breakfast','sentiment': 'excellent'}, {'aspect': 'room','sentiment':'small'}, {'aspect': 'air conditioning','sentiment': 'not working properly'}].  If there are multiple sentences, the functions should extract the aspects and sentiments from each sentence separately.  For example, \"The hotel is great. The staff is friendly.\" would return [{'aspect': 'hotel','sentiment': 'great'}, {'aspect':'staff','sentiment': 'friendly'}]. \n",
      "\n",
      "Note: The output list of dictionaries will always be in the same order as the input sentences.  For example, if the input text is \"The hotel is great. The staff is friendly.\" the output will be [{'aspect': 'hotel','sentiment': 'great'}, {'aspect':'staff','sentiment': 'friendly'}], not [{'aspect':'staff',\n",
      "  ]\n",
      "\n",
      "\n",
      "\n",
      "[\n",
      "    {'aspect': 'interesting','sentiment': ''},\n",
      "    {'aspect': 'immortal','sentiment': ''}\n",
      "]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ]  ] \n",
      "\n",
      "\n",
      "\n",
      "Here is the input text: \n",
      "\"Yes. Fish is the important resources of human world wide for the commercial and subsistence fish hunts the fish in the wild fisheries.\"\n",
      "\n",
      "The corresponding output:\n",
      "[{'aspect':'resources','sentiment': 'important'}]  // because'resources' is the only aspect mentioned in the text with a sentiment.  // 'fish' is not an aspect, it is a noun, and 'wild' is an adjective describing 'fisheries', so they are not aspects either.\n",
      " \n",
      "\n",
      "Output:\n",
      "[\n",
      "  {'aspect': 'cats','sentiment': 'like'}\n",
      "]  # or {'aspect': 'dogs','sentiment': 'fan'}\n",
      "]  # because the sentiment is implied but not explicitly mentioned. \n",
      "]  # If you can't infer the sentiment, you can leave it as is. For example, {'aspect': 'cats','sentiment': ''}.  # or None, or 'neutral', or 'unknown'...  # It's up to you.  # The most important thing is to return a list of dictionaries.  # The dictionary should have at least two keys, 'aspect' and'sentiment'.  # The 'aspect' key should have a string value representing the aspect or feature mentioned in the text.  # The'sentiment' key should have a string value representing the sentiment expressed towards the aspect.  # The sentiment can be positive, negative, neutral, implied, or unknown.  # The aspect and sentiment values should be based on the input text.  # The output should be a list of dictionaries, with each dictionary representing an aspect and its sentiment.  # The order of the dictionaries in the list is not important.  # You can use any approach to extract the aspects and their related sentiment from the input text.  # You can also use any language model or NLP library to help you with the task.  # The most important thing is to return a list of dictionaries that represents the aspects and their related sentiment.  # You can use any data structure you want, but the output should be a list of dictionaries.  # You can use a dictionary, list, or any other data structure you want.  # The output should be a list of dictionaries, with each dictionary having at least two keys, 'aspect' and'sentiment'.  # You can use any approach to extract the aspects and their related sentiment from the input text.  # You can also use any language model or NLP library to help you with the task.  # The most important thing is to return a list of dictionaries that represents the aspects and their related sentiment.  # You can use any data structure you want, but the output should be a list of dictionaries.  # You can use a dictionary, list, or any other data structure you want.  # The output should be a list of dictionaries, with each dictionary having at least two keys, 'aspect' and'sentiment'.  # You can use any approach\n",
      "\n",
      "\n",
      "\n",
      "The corresponding output for the given text: [{'aspect': 'cleanliness','sentiment':'very clean'}]\n",
      " \n",
      "\n",
      "Please provide the output for the given input. \n",
      "\n",
      "[{'aspect': 'time','sentiment': 'a lot'}] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Please provide the output for the following inputs:\n",
      "\n",
      "Input 1: \"Cats can be cool, but they sure do spend a lot of their time sleeping.\"\n",
      "\n",
      "Output 1: [({'aspect': 'time','sentiment': 'a lot'}, {'aspect': 'time','sentiment':'sleeping'})]\n",
      "\n",
      "Input 2: \"The food was delicious, but the service was poor.\"\n",
      "\n",
      "Output 2: [({'aspect': 'food','sentiment': 'delicious'}, {'aspect':'service','sentiment': 'poor'})]\n",
      "\n",
      "Input 3: \"The hotel room was nice, but the location was terrible.\"\n",
      "\n",
      "Output 3: [({'aspect': 'hotel room','sentiment': 'nice'}, {'aspect': 'location','sentiment': 'terrible'})]\n",
      "\n",
      "Input 4: \"The hotel was beautiful, but the price was too high.\"\n",
      "\n",
      "Output 4: [({'aspect': 'hotel','sentiment': 'beautiful'}, {'aspect': 'price','sentiment': 'too high'})]\n",
      "\n",
      "Input 5: \"The movie was boring, but the special effects were amazing.\"\n",
      "\n",
      "Output 5: [({'aspect':'movie','sentiment': 'boring'}, {'aspect':'special effects','sentiment': 'amazing'})]\n",
      "\"\n",
      "\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'faint'},\n",
      "    {'aspect': 'hearing','sentiment': 'high frequency'}]  # solution 1\n",
      "[\n",
      "    {'aspect':'sound','sentiment': 'too faint'},\n",
      "    {'aspect':'sound','sentiment': 'too high frequency'}]  # solution 2\n",
      "[\n",
      "    {'aspect': 'frequency','sentiment': 'high'},\n",
      "    {'aspect': 'frequency','sentiment': 'faint'}]  # solution 3\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'human ears can hear'}]  # solution 4\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'human ears can hear'}]  # solution 5\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'too faint'},\n",
      "    {'aspect': 'hearing','sentiment': 'too high frequency'}]  # solution 6\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'too faint or too high frequency'}]  # solution 7\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'human ears can hear'}]  # solution 8\n",
      "[\n",
      "    {'aspect':'sound','sentiment': 'too high frequency'},\n",
      "    {'aspect':'sound','sentiment': 'too faint'}]  # solution 9\n",
      "[\n",
      "    {'aspect': 'frequency','sentiment': 'too high frequency'},\n",
      "    {'aspect': 'frequency','sentiment': 'too faint'}]  # solution 10\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'too high frequency'},\n",
      "    {'aspect': 'hearing','sentiment': 'too faint'}]  # solution 11\n",
      "[\n",
      "    {'aspect':'sound','sentiment': 'human ears can hear'}]  # solution 12\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'too high frequency or too faint'}]  # solution 13\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'too high frequency or too faint'}]  # solution 14\n",
      "[\n",
      "    {'aspect':'sound','sentiment': 'human ears can hear'}]  # solution 15\n",
      "[\n",
      "    {'aspect': 'hearing','sentiment': 'too high frequency or too faint'}] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m all_aspects_and_sentiments \u001b[39m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m30\u001b[39m]:\n\u001b[0;32m---> 23\u001b[0m     result \u001b[39m=\u001b[39m extract_aspects_and_sentiments(sentence)\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m     25\u001b[0m     all_aspects_and_sentiments\u001b[39m.\u001b[39mappend(result)\n",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m, in \u001b[0;36mextract_aspects_and_sentiments\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     15\u001b[0m example_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThe hotel\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms location was perfect, the staff were friendly and helpful, the breakfast was excellent, but the room was small and the air conditioning was not working properly. The hotel\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms gym was not very good and the pool was cold.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtract aspects and their related adjective from the following text:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOnly return the result as a list of dictionaries with \u001b[39m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, without explanations and code.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mAn example input is: \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00mexample_text\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThe corresponding output: \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocation\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mperfect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mstaff\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhelpful\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbreakfast\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mexcellent\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mroom\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39msmall\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mair conditioning\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot working properly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mgym\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot very good\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpool\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcold\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m response \u001b[39m=\u001b[39m llm\u001b[39m.\u001b[39;49minvoke(prompt)\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    277\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    278\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    279\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    280\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    281\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    282\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    283\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    284\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    285\u001b[0m         )\n\u001b[1;32m    286\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    804\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    805\u001b[0m     )\n\u001b[1;32m    806\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    658\u001b[0m                 prompts,\n\u001b[1;32m    659\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    660\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    662\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    663\u001b[0m             )\n\u001b[1;32m    664\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/llms.py:1322\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1320\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m   1321\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1322\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1323\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1324\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m   1327\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_huggingface/llms/huggingface_endpoint.py:258\u001b[0m, in \u001b[0;36mHuggingFaceEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     invocation_params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m invocation_params[\n\u001b[1;32m    256\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstop_sequences\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m     ]  \u001b[39m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m    259\u001b[0m         json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt, \u001b[39m\"\u001b[39;49m\u001b[39mparameters\u001b[39;49m\u001b[39m\"\u001b[39;49m: invocation_params},\n\u001b[1;32m    260\u001b[0m         stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    261\u001b[0m         task\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask,\n\u001b[1;32m    262\u001b[0m     )\n\u001b[1;32m    263\u001b[0m     response_text \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mdecode())[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    265\u001b[0m     \u001b[39m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[39m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/inference/_client.py:259\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mwith\u001b[39;00m _open_as_binary(data) \u001b[39mas\u001b[39;00m data_as_binary:\n\u001b[1;32m    258\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m         response \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m    260\u001b[0m             url,\n\u001b[1;32m    261\u001b[0m             json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    262\u001b[0m             data\u001b[39m=\u001b[39;49mdata_as_binary,\n\u001b[1;32m    263\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    264\u001b[0m             cookies\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcookies,\n\u001b[1;32m    265\u001b[0m             timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    266\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    267\u001b[0m         )\n\u001b[1;32m    268\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m    269\u001b[0m         \u001b[39m# Convert any `TimeoutError` to a `InferenceTimeoutError`\u001b[39;00m\n\u001b[1;32m    270\u001b[0m         \u001b[39mraise\u001b[39;00m InferenceTimeoutError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInference call timed out: \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror\u001b[39;00m  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:66\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     68\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    794\u001b[0m     conn,\n\u001b[1;32m    795\u001b[0m     method,\n\u001b[1;32m    796\u001b[0m     url,\n\u001b[1;32m    797\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    798\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    799\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    800\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    801\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    802\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    803\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    804\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    805\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    806\u001b[0m )\n\u001b[1;32m    808\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    538\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    468\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1134\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "data = pd.read_csv(\"../data/topical_chat.csv\").drop(columns=[\"sentiment\", \"conversation_id\"])\n",
    "\n",
    "# Initialize HuggingFaceEndpoint\n",
    "huggingfacehub_api_token = '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'\n",
    "llm = HuggingFaceEndpoint(repo_id='meta-llama/Meta-Llama-3-8B-Instruct', huggingfacehub_api_token=huggingfacehub_api_token)\n",
    "\n",
    "# Define the function for aspect extraction and sentiment analysis\n",
    "def extract_aspects_and_sentiments(text):\n",
    "    example_text = \"The hotel's location was perfect, the staff were friendly and helpful, the breakfast was excellent, but the room was small and the air conditioning was not working properly. The hotel's gym was not very good and the pool was cold.\"\n",
    "    prompt = f\"Extract aspects and their related adjective from the following text:\\n\\n{text}\\n\\nOnly return the result as a list of dictionaries with 'aspect' and 'sentiment', without explanations and code.\\n\\nAn example input is: \\\"{example_text}\\\"\\nThe corresponding output: \\\"[{{'aspect': 'location', 'sentiment': 'perfect'}}, {{'aspect': 'staff', 'sentiment': 'helpful'}}, {{'aspect': 'breakfast', 'sentiment': 'excellent'}}, {{'aspect': 'room', 'sentiment': 'small'}}, {{'aspect': 'air conditioning', 'sentiment': 'not working properly'}}, {{'aspect': 'gym', 'sentiment': 'not very good'}}, {{'aspect': 'pool', 'sentiment': 'cold'}}]\\\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "all_aspects_and_sentiments = []\n",
    "\n",
    "for sentence in data['message'][:30]:\n",
    "    result = extract_aspects_and_sentiments(sentence)\n",
    "    print(result)\n",
    "    all_aspects_and_sentiments.append(result)\n",
    "\n",
    "# Print the results\n",
    "for aspects_and_sentiments in all_aspects_and_sentiments:\n",
    "    print(aspects_and_sentiments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      " Are you a fan of Google or Microsoft?\n",
      "[]\n",
      " Both are excellent technology they are helpful in many ways. For the security purpose both are super.\n",
      "[{'aspect': 'technology', 'sentiment': 'excellent'}, {'aspect': 'ways', 'sentiment': 'many'}]\n",
      " I'm not  a huge fan of Google, but I use it a lot because I have to. I think they are a monopoly in some sense. \n",
      "[{'aspect': 'fan', 'sentiment': 'huge'}]\n",
      " Google provides online related services and products, which includes online ads, search engine and cloud computing.\n",
      "[{'aspect': 'services', 'sentiment': 'related'}, {'aspect': 'ads', 'sentiment': 'online'}]\n",
      " Yeah, their services are good. I'm just not a fan of intrusive they can be on our personal lives. \n",
      "[{'aspect': 'lives', 'sentiment': 'personal'}]\n",
      " Google is leading the alphabet subsidiary and will continue to be the Umbrella company for Alphabet internet interest.\n",
      "[]\n",
      " Did you know Google had hundreds of live goats to cut the grass in the past? \n",
      "[{'aspect': 'goats', 'sentiment': 'live'}, {'aspect': 'hundreds', 'sentiment': 'cut'}]\n",
      " It is very interesting. Google provide \"Chrome OS\" which is a light weight OS. Google provided a lot of hardware mainly in 2010 to 2015. \n",
      "[{'aspect': 'OS', 'sentiment': 'light'}]\n",
      " I like Google Chrome. Do you use it as well for your browser? \n",
      "[]\n",
      " Yes.Google is the biggest search engine and Google service figure out top 100 website, including Youtube and Blogger.\n",
      "[{'aspect': 'engine', 'sentiment': 'biggest'}, {'aspect': 'website', 'sentiment': 'top'}]\n",
      " By the way, do you like Fish? \n",
      "[]\n",
      " Yes. They form a sister group of tourniquets- they make the sea water clean and remove the dust from it. Fish is the biggest part in the eco-system.\n",
      "[{'aspect': 'part', 'sentiment': 'biggest'}]\n",
      " Did you know that a seahorse is the only fish to have a neck? \n",
      "[{'aspect': 'fish', 'sentiment': 'only'}]\n",
      " Freshwater fish only drink water through the skin via Osmosis, Saltwater fish drink water through the mouth. Dolphins are friendly to human beings.\n",
      "[{'aspect': 'beings', 'sentiment': 'human'}]\n",
      " Interesting, they also have gills. Did you know that jellyfish are immortal? \n",
      "[]\n",
      " Yes. Fish is the important resources of human world wide for the commercial and subsistence fish hunts the fish in the wild fisheries.\n",
      "[{'aspect': 'resources', 'sentiment': 'important'}, {'aspect': 'world', 'sentiment': 'human'}, {'aspect': 'fish', 'sentiment': 'commercial'}, {'aspect': 'fisheries', 'sentiment': 'wild'}]\n",
      " What about cats, do you like cats? I'm a dog fan myself. \n",
      "[]\n",
      " The cat is referred as domestic cat and wild cat. They make our world very clean from rats! \n",
      "[{'aspect': 'cat', 'sentiment': 'domestic'}]\n",
      " Yeah, cats can be cool, but they sure do spend a lot of their time sleeping. \n",
      "[]\n",
      " Cats hear the sounds too faint or too high frequency human ears can hear. \n",
      "[{'aspect': 'ears', 'sentiment': 'frequency'}]\n",
      " I heard that too. Well, it was nice chatting with you. Have a good day. \n",
      "[{'aspect': 'chatting', 'sentiment': 'nice'}, {'aspect': 'day', 'sentiment': 'good'}]\n",
      " do you like dance?\n",
      "[]\n",
      " Yes  I do. Did you know Bruce Lee was a cha cha dancer?\n",
      "[]\n",
      " Yes he even won a hardcore cha cha championship in 1958\n",
      "[{'aspect': 'championship', 'sentiment': 'hardcore'}]\n",
      " Yeah. Did you know Tupac was a ballet dancer?\n",
      "[]\n",
      " Yes and he even was in the production of the nutcracker\n",
      "[]\n",
      " Yeah. Ballet dancer go through 4 pairs of shoes a week\n",
      "[]\n",
      " Yes that is a lot of shoes and also a lot of money\n",
      "[]\n",
      " Yeah true. Did you know babies are really good at dancing?\n",
      "[]\n",
      " Yes and they smile more when they hit the beat\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to extract aspects and sentiments (adjectives)\n",
    "def extract_aspects_and_sentiments(text):\n",
    "    doc = nlp(text)\n",
    "    aspects_sentiments = []\n",
    "    seen_aspects = set()  # To track unique aspects encountered\n",
    "    \n",
    "    for token in doc:\n",
    "        # Check for adjectives describing a noun\n",
    "        if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\":\n",
    "            aspect = token.head.text\n",
    "            sentiment = token.text\n",
    "            if aspect not in seen_aspects:\n",
    "                aspects_sentiments.append({'aspect': aspect, 'sentiment': sentiment})\n",
    "                seen_aspects.add(aspect)\n",
    "        \n",
    "        # Check for verbs or adjectives near the noun\n",
    "        elif token.pos_ in [\"VERB\", \"ADJ\"] and token.head.pos_ == \"NOUN\":\n",
    "            aspect = token.head.text\n",
    "            sentiment = token.text\n",
    "            if aspect not in seen_aspects:\n",
    "                aspects_sentiments.append({'aspect': aspect, 'sentiment': sentiment})\n",
    "                seen_aspects.add(aspect)\n",
    "    \n",
    "    return aspects_sentiments\n",
    "\n",
    "# Example dataset\n",
    "data = pd.read_csv(\"../data/topical_chat.csv\").drop(columns=[\"sentiment\", \"conversation_id\"])\n",
    "\n",
    "# Extract aspects and sentiments from the dataset\n",
    "all_aspects_and_sentiments = []\n",
    "\n",
    "print(extract_aspects_and_sentiments(\"The movie was boring and the plot was confusing\"))\n",
    "# Process a subset of data for demonstration (adjust as needed)\n",
    "for sentence in data['message'][:30]:\n",
    "    print(sentence)\n",
    "    result = extract_aspects_and_sentiments(sentence)\n",
    "    print(result)\n",
    "    all_aspects_and_sentiments.extend(result)\n",
    "\n",
    "# Print the results\n",
    "# print(\"Extracted aspects and sentiments:\")\n",
    "# for aspect_sentiment in all_aspects_and_sentiments:\n",
    "#     print(aspect_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from jinja2->spacy) (2.1.4)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.21.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.4)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    3.7.5                         \n",
      "Location         /Users/mahcheeteng/anaconda3/envs/CS2109S/lib/python3.9/site-packages/spacy\n",
      "Platform         macOS-13.4.1-arm64-arm-64bit  \n",
      "Python version   3.9.9                         \n",
      "Pipelines        en_core_web_sm (3.7.1)        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18 (main, Sep 11 2023, 08:38:23) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f699e79cfe9206a791baf8495c1fe24c480c72c46ac70180783435d651c2a74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
